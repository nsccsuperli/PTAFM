{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import config\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# GPT-3 XL\n",
    "batch_size = 1e6 / 2048\n",
    "layer_size = 24\n",
    "\n",
    "# physical topology\n",
    "num_devices = 64 \n",
    "peer_delay = None\n",
    "peer_bandwidth = None\n",
    "regions = None\n",
    "\n",
    "# assigned task\n",
    "batch_size_per_task = 1.25e5 / 2048\n",
    "layer_size_per_task = 3\n",
    "send_gradient_size = 1.3 * np.dtype(np.float32).itemsize * layer_size_per_task / layer_size  # gigabytes\n",
    "send_activation_size = 2024 * 2048 * np.dtype(np.float16).itemsize * batch_size_per_task / (1024 * 1024 * 1024)  # gigabytes\n",
    "\n",
    "assert(batch_size % batch_size_per_task == 0)\n",
    "assert(layer_size % layer_size_per_task == 0)\n",
    "assert(num_devices == batch_size * layer_size / (batch_size_per_task * layer_size_per_task))\n",
    "\n",
    "way = int(layer_size / layer_size_per_task) # 8\n",
    "partition_size = int(batch_size / batch_size_per_task) # 8\n",
    "\n",
    "### GA config\n",
    "num_devices = 64\n",
    "population_size=100\n",
    "nodes=list(range(num_devices))\n",
    "trails=4900\n",
    "mode=\"default\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidate_partitions, all_cost_records, min_cost_records = GCMA(nodes=list(range(num_devices)), population_size=100, trails=4900, mode=\"default\")\n",
    "candidate_partitions = []\n",
    "candidate_scores = []\n",
    "candidate_min_scores = []\n",
    "\n",
    "for i in range(population_size):\n",
    "    cur_nodes = nodes.copy()    # range的node结点 复制种群数量份\n",
    "    random.seed = i             # SEED\n",
    "    random.shuffle(cur_nodes)   # 打乱顺序\n",
    "    candidate_partitions.append(cur_nodes)  # 所有种群放在candidate_partitions中 是个list，【100，64】\n",
    "    \n",
    "for i, candidate_partition in enumerate(candidate_partitions):\n",
    "    # 将[1...64] 变为 [1..7, 7...15,  ..... , 56...63]\n",
    "    candidate_partition = [candidate_partition[i: i + partition_size] for i in range(0, num_devices, partition_size)]   \n",
    "    \n",
    "    # 计算dp和pp的cost\n",
    "    # data_parallel_cost = compute_data_parallel_cost(candidate_partition=candidate_partition)  \n",
    "    # pipeline_parallel_cost, pipeline_parallel_path, pipeline_parallel_match = compute_pipeline_parallel_cost(candidate_partition)\n",
    "    \n",
    "    ## 综合cost -> scores = dp + pp !!! 可以考虑一下这个改进地方\n",
    "    candidate_scores.append(data_parallel_cost +2 * pipeline_parallel_cost)\n",
    "    candidate_min_scores.append(np.min(candidate_scores))\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
